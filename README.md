# Overview of Data Engineering Projects

This repository consolidates the main characteristics of two prominent Data Engineering projects:

## 1. IBM Data Engineering Capstone Project

In this project, participants assume the role of a Junior Data Engineer working for SoftCart, a fictional e-commerce company. The project emphasizes applying industry-standard data engineering solutions to real-world use cases.

### Key Objectives
- Demonstrate proficiency in entry-level data engineering skills.
- Design and implement data repositories and pipelines.
- Work with relational databases, NoSQL data stores, big data engines, and data warehouses.
- Utilize Linux shell scripting, SQL, and Python to solve Data Engineering problems.

### Project Highlights
- **OLTP Database:** MySQL to store inventory and sales data.
- **NoSQL Database:** MongoDB for catalog data.
- **Data Warehousing:** PostgreSQL (staging) and IBM Db2 (production).
- **Big Data Platform:** Hadoop cluster analyzed using Spark.
- **ETL Pipelines:** Managed with Apache Airflow.
- **BI Dashboards:** Created using IBM Cognos Analytics.

#### Assignments
1. **MySQL Online Transactional Processing Database:** Design schema, index, and automate data export.
2. **MongoDB NoSQL Catalog Database:** Import and query catalog data.
3. **PostgreSQL Staging Data Warehouse:** Design a star schema and load data.
4. **IBM Db2 Production Data Warehouse:** Load data and create materialized views.
5. **Python Scripts & Automation:** Sync data between staging and production databases.
6. **Apache Airflow ETL Pipelines:** Analyze and process web server logs.
7. **Apache Spark Big Data Analytics:** Forecast sales using PySpark and a pretrained model.

---

## 2. Cloud Data Engineer Bootcamp - IGTI (Module 1)

This module focuses on cloud data architecture fundamentals, offering hands-on experience with modern tools and practices.

### Use Cases
1. **Delta Lake with EMR:** Implement a scalable data lake architecture.
   - Solution Architecture:
     ![delta](1_XP_BootCamp_Data_Engineering/img/edc_mod1_delta.png)

2. **Event Streaming with Kinesis:** Process and analyze streaming event data.
   - Solution Architecture:
     ![kinesis](1_XP_BootCamp_Data_Engineering/img/edc_mod1_delta-kinesis.png)

3. **Big Data Pipeline Orchestration with Airflow:** Automate and manage data workflows.
   - Solution Architecture:
     ![airflow](1_XP_BootCamp_Data_Engineering/img/edc_mod1_delta-airflow.png)

---

## Tools/Technologies Used
- **Relational Databases:** MySQL, PostgreSQL, IBM Db2.
- **NoSQL Database:** MongoDB.
- **Big Data Platforms:** Hadoop, Spark.
- **Data Pipeline Orchestration:** Apache Airflow.
- **Business Intelligence:** IBM Cognos Analytics.

These projects collectively cover the end-to-end lifecycle of data engineering workflows, from OLTP and NoSQL systems to cloud-based data warehouses and big data analytics.


